# AnÃ¡lisis: Por QuÃ© las Features OSM Empeoraron el Modelo

**Fecha**: 14 de noviembre de 2025
**Resultado Inesperado**: Features OSM degradaron RÂ² de -0.69 â†’ -37.90 (Lasso)

---

## ğŸ“Š Resultados Observados

### ComparaciÃ³n Baseline vs Enhanced

| Modelo | VersiÃ³n | Features | RÂ² | RMSE | MAE |
|--------|---------|----------|-----|------|-----|
| **Lasso** | Baseline | 13 | **-0.69** | 25.08 | 20.98 |
| **Lasso** | Enhanced | 18 | **-37.90** âŒ | 63.00 | 59.43 |
| **XGBoost** | Baseline | 13 | **-1.87** | 26.28 | 22.26 |
| **XGBoost** | Enhanced | 18 | **-2.23** âŒ | 28.19 | 23.82 |

### Observaciones

1. **Lasso se degrada drÃ¡sticamente** (-0.69 â†’ -37.90): -5,361% peor
2. **XGBoost se degrada moderadamente** (-1.87 â†’ -2.23): -19% peor
3. Ambos modelos empeoran, pero **Lasso colapsa**

---

## ğŸ” HipÃ³tesis: Â¿Por QuÃ© Empeoraron?

### HipÃ³tesis 1: Multicolinealidad Extrema

**Problema**: Las features OSM estÃ¡n **altamente correlacionadas** entre sÃ­ y con features existentes.

**Features OSM agregadas**:
1. `dist_to_highway_km` - Distancia a autopista
2. `dist_to_primary_km` - Distancia a vÃ­a primaria
3. `road_density_500m` - Densidad vial 500m
4. `road_density_1km` - Densidad vial 1km
5. `highway_count_1km` - NÃºmero de autopistas 1km

**Correlaciones esperadas**:
- `dist_to_highway_km` â†” `highway_count_1km`: CorrelaciÃ³n negativa alta (-0.8 a -0.9)
- `road_density_500m` â†” `road_density_1km`: CorrelaciÃ³n positiva alta (0.9+)
- `road_density` â†” `distance_to_center_km` (ya existente): Negativa alta (-0.7+)

**Efecto en Lasso**:
- Lasso regularizaciÃ³n L1 â†’ Penaliza coeficientes altos
- Con features correlacionadas, Lasso puede "saltar" entre features equivalentes
- Resultado: inestabilidad numÃ©rica, coeficientes extremos

**Efecto en XGBoost**:
- Tree-based models mÃ¡s robustos a correlaciÃ³n
- Pero aÃºn asÃ­ sufren si features redundantes confunden splits

---

### HipÃ³tesis 2: Features EstÃ¡ticas vs Variables Temporales

**Problema**: Features OSM son **estÃ¡ticas** (no varÃ­an en el tiempo para cada estaciÃ³n).

**ImplicaciÃ³n**:
- En LOSO-CV, modelo entrena en 7 estaciones, predice en 1
- Features estÃ¡ticas solo capturan diferencia ENTRE estaciones, no DENTRO
- Si estaciÃ³n de test es muy diferente â†’ modelo sobre-generaliza patrones de training

**Ejemplo**:
- Las Condes: `dist_to_highway_km` = 0.13 km, muy cercana
- Talagante: `dist_to_highway_km` = 3.01 km, muy lejana

Modelo aprende: "cerca de autopista â†’ PM2.5 alto"
Pero en Las Condes: PM2.5 es **bajo** (zona residencial alta, poco trÃ¡fico local)

â†’ Modelo falla porque **contexto local** domina sobre proximidad a autopista

---

### HipÃ³tesis 3: Escala de Features Incompatible

**Problema**: Features OSM tienen escalas muy diferentes.

**Rangos observados** (de estadÃ­sticas):
- `dist_to_highway_km`: 0.13 - 3.01 km (range: 2.88)
- `dist_to_primary_km`: 0.008 - 2.94 km (range: 2.93)
- `road_density_500m`: 0.5 - 53.7 km/kmÂ² (range: 53.2) âš ï¸
- `road_density_1km`: 7.0 - 50.7 km/kmÂ² (range: 43.7)
- `highway_count_1km`: 0 - 43 (range: 43)

**Problema**: Aunque usamos `StandardScaler`, features con valores extremos (Cerro Navia: density=53.7) pueden dominar.

---

### HipÃ³tesis 4: Overfitting a Estaciones de Training

**Problema**: Con solo **8 estaciones**, agregar 5 features mÃ¡s (40% aumento) causa overfitting espacial.

**Evidencia**:
- Baseline: 13 features para 8 estaciones (1.6 feat/station)
- Enhanced: 18 features para 8 estaciones (2.25 feat/station)

Lasso necesita **regularizaciÃ³n mÃ¡s fuerte** con mÃ¡s features.

---

## ğŸ§ª VerificaciÃ³n de HipÃ³tesis

### 1. Verificar Multicolinealidad

Necesitamos calcular correlaciones entre features OSM y existentes.

**Script sugerido**:
```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('data/processed/sinca_features_spatial_enhanced.csv')

# Features numÃ©ricas
osm_features = ['dist_to_highway_km', 'dist_to_primary_km',
                'road_density_500m', 'road_density_1km', 'highway_count_1km']

existing_features = ['distance_to_center_km', 'lat', 'lon',
                     'elevation', 'wind_direction_rad']

all_features = osm_features + existing_features

# CorrelaciÃ³n
corr_matrix = df[all_features].corr()

# Heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)
plt.title('Correlation Matrix: OSM + Existing Features')
plt.tight_layout()
plt.savefig('reports/figures/osm_correlation_matrix.png', dpi=150)
```

---

### 2. Verificar Varianza por EstaciÃ³n

Â¿CuÃ¡nta variabilidad tienen features OSM DENTRO de cada estaciÃ³n?

```python
# Por estaciÃ³n
for station in df['estacion'].unique():
    station_data = df[df['estacion'] == station]

    # Varianza de features OSM
    osm_variance = station_data[osm_features].var()

    print(f"{station}:")
    print(osm_variance)
```

**HipÃ³tesis**: Varianza = 0 (features estÃ¡ticas) â†’ No aportan informaciÃ³n temporal.

---

### 3. VIF (Variance Inflation Factor)

Calcular VIF para detectar multicolinealidad:

```python
from statsmodels.stats.outliers_influence import variance_inflation_factor

X = df[all_features].dropna()

vif_data = pd.DataFrame()
vif_data["Feature"] = all_features
vif_data["VIF"] = [variance_inflation_factor(X.values, i)
                   for i in range(len(all_features))]

print(vif_data.sort_values('VIF', ascending=False))
```

**InterpretaciÃ³n**:
- VIF > 10: Multicolinealidad alta
- VIF > 100: Multicolinealidad extrema

---

## ğŸ’¡ Soluciones Propuestas

### SoluciÃ³n 1: Feature Selection Agresiva

**Eliminar features redundantes**:

Mantener solo:
- `dist_to_highway_km` (eliminar `dist_to_primary_km`)
- `road_density_1km` (eliminar `road_density_500m`)
- Eliminar `highway_count_1km` (redundante con distancia)

**Resultado**: 3 features OSM en lugar de 5

---

### SoluciÃ³n 2: RegularizaciÃ³n MÃ¡s Fuerte

**Aumentar alpha en Lasso**:

```python
# Probar diferentes alphas
alphas = [0.1, 1.0, 10.0, 100.0]

for alpha in alphas:
    model = Lasso(alpha=alpha, max_iter=5000)
    # Evaluar...
```

**HipÃ³tesis**: alpha=1.0 es insuficiente con 18 features.

---

### SoluciÃ³n 3: PCA o Feature Extraction

**Reducir dimensionalidad**:

```python
from sklearn.decomposition import PCA

# PCA en features OSM
pca = PCA(n_components=2)  # Reducir 5 â†’ 2
osm_pca = pca.fit_transform(df[osm_features])

# Usar componentes principales
df['osm_pc1'] = osm_pca[:, 0]
df['osm_pc2'] = osm_pca[:, 1]
```

**Ventaja**: Elimina multicolinealidad, mantiene varianza.

---

### SoluciÃ³n 4: Interacciones en Lugar de Raw Features

**En lugar de agregar features crudas, crear interacciones**:

```python
# InteracciÃ³n: densidad vial Ã— distancia al centro
df['road_density_center_interaction'] = (
    df['road_density_1km'] * (1 / (1 + df['distance_to_center_km']))
)

# Solo agregar ESTA feature (1 en lugar de 5)
```

**Ventaja**: Captura relaciÃ³n no-lineal, menos features.

---

### SoluciÃ³n 5: Usar Features OSM Solo en Modelos No-Lineales

**HipÃ³tesis**: Tree-based models manejan mejor redundancia que Lasso.

**Estrategia**:
- Lasso: Solo features originales (13)
- XGBoost/Random Forest: Features originales + OSM (18)

**Resultado esperado**: XGBoost mejora (aunque modestamente).

---

## ğŸ¯ Plan de AcciÃ³n

### Paso 1: DiagnÃ³stico (Inmediato)

1. **Calcular matriz de correlaciÃ³n** OSM + existentes
2. **Calcular VIF** para detectar multicolinealidad
3. **Inspeccionar varianza** por estaciÃ³n (verificar si son estÃ¡ticas)

### Paso 2: CorrecciÃ³n (Basado en diagnÃ³stico)

**Si multicolinealidad alta (VIF > 10)**:
â†’ Aplicar SoluciÃ³n 1 o 3 (feature selection o PCA)

**Si features estÃ¡ticas (var â‰ˆ 0 por estaciÃ³n)**:
â†’ Las features OSM NO ayudan en LOSO-CV
â†’ Solo Ãºtiles si agregamos variabilidad temporal (ej: trÃ¡fico horario)

**Si escala es problema**:
â†’ Aplicar transformaciÃ³n log o rank-based

### Paso 3: Re-evaluaciÃ³n

Probar combinaciones:
1. Baseline (13 features)
2. Reduced OSM (13 + 2 seleccionadas)
3. OSM + PCA (13 + 2 componentes)
4. OSM + interacciones (13 + 1 interacciÃ³n)

**Meta**: Mejorar RÂ² de -0.69 â†’ -0.40 a 0.00 (mÃ¡s realista que +0.30)

---

## ğŸ“Š Lecciones Aprendidas

### 1. MÃ¡s Features â‰  Mejor Modelo

Con **solo 8 estaciones**, agregar features puede causar:
- Overfitting espacial
- Multicolinealidad
- Inestabilidad numÃ©rica

**Regla prÃ¡ctica**: n_features < n_samples / 10
- 8 estaciones â†’ mÃ¡ximo ~1 feature
- 16,344 observaciones pero agrupadas en 8 estaciones â†’ efectivamente n=8 para generalizaciÃ³n espacial

### 2. Features EstÃ¡ticas InÃºtiles para LOSO-CV

Features que NO varÃ­an temporalmente dentro de estaciÃ³n:
- No ayudan a predecir variabilidad temporal
- Solo Ãºtiles para diferencias ENTRE estaciones
- En LOSO-CV, modelo nunca ve la estaciÃ³n de test â†’ features estÃ¡ticas no transfieren

**SoluciÃ³n**: Necesitamos features que varÃ­en TEMPORALMENTE:
- TrÃ¡fico por hora del dÃ­a
- NDVI mensual (estacional)
- MeteorologÃ­a (varÃ­a diariamente)

### 3. Validar SIEMPRE Antes de Asumir Mejora

Asumimos "trÃ¡fico = importante" pero:
- Proximidad a autopista NO captura trÃ¡fico real
- Contexto local (Las Condes: residencial vs Cerro Navia: industrial) domina
- Features proxy pueden no correlacionar con target

---

## âœ… ConclusiÃ³n

**Las features OSM empeoraron el modelo por**:
1. **Multicolinealidad** (5 features correlacionadas)
2. **Features estÃ¡ticas** (no varÃ­an temporalmente)
3. **Overfitting** (18 features para 8 estaciones)

**PrÃ³ximos pasos**:
1. Calcular correlaciones/VIF (diagnÃ³stico)
2. Reducir a 2-3 features OSM seleccionadas
3. Intentar features TEMPORALES (NDVI, poblaciÃ³n con variaciÃ³n horaria)
4. Considerar modelos geoestadÃ­sticos (Kriging) que NO dependen de features

---

**Archivo**: `docs/OSM_FEATURES_ANALYSIS.md`
**Status**: AnÃ¡lisis completado, soluciones propuestas
**AcciÃ³n inmediata**: Ejecutar diagnÃ³stico de correlaciÃ³n/VIF
